view(mpg)
mpg %>%
group_by(class) %>%
summarise(mean(cty))
view(mpg)
mpg_metric <- mpg %>%
mutate(cty_metric = 0.425144 * cty)
view(mpg_metric)
mpg_metric <- mpg %>%
mutate(test = 0.425144 * cty)
view(mpg_metric)
mpg %>%
group_by(class) %>%
summarise(mean(cty))
view(mpg)
mpg %>%
group_by(class) %>%
mutate(averange = summarise(mean(cty)))
mpg %>%
group_by(class) %>%
mutate(test = summarise(mean(cty)))
latest_mpg <- mpg %>%
group_by(class) %>%
mutate(test = summarise(mean(cty)))
latest_mpg <- mpg %>%
group_by(class) %>%
mutate(test = summarise(mean(cty)))
latest_mpg <- mpg %>%
group_by(class) %>%
mutate(test = mean(cty))
head(latest_mpg)
view(latest_mpg)
head(latest_mpg)
mpg_metric <- mpg %>%
group_by(class) %>%
summarise(mean(cty))
mpg %>%
group_by(class) %>%
summarise(mean(cty))
mpg %>%
group_by(class) %>%
summarise(mean(cty),
median(cty))
mean(numbers)
print(result)
result <- mean(numbers)
numbers <- c(1, 2, 3, 4, 5)
result <- mean(numbers)
print(result)
numbers <- c(1, 2, 3, 4, 5, 6)
numbers <- c(1, 2, 3, 4, 5, 6)
result <- mean(numbers)
print(result)
for (i in numbers){
print(i)
}
for (i in numbers){
numberAdd += numbers
for (i in numbers){
numberAdd += i
for (i in numbers){
numberAdd = numberAdd + i
}
numberAdd <- 0
for (i in numbers){
numberAdd = numberAdd + i
}
print(numberAdd)
numberAdd/numbers
mpg %>%
group_by(class) %>%
summarise(mean(cty),
median(cty))
# Data Viz with ggplot2
ggplot(mpg, aes(x=cty))
# Data Viz with ggplot2
ggplot(mpg, aes(x=cty)) +
geom_histogram()
# Data Viz with ggplot2
ggplot(mpg, aes(x=cty)) +
geom_histogram() +
labs(x = "City mileage")
# Data Viz with ggplot2
ggplot(mpg, aes(x=cty)) +
geon_freqpoly() +
labs(x = "City mileage")
# Data Viz with ggplot2
ggplot(mpg, aes(x=cty)) +
geom_freqpoly() +
labs(x = "City mileage")
# Data Viz with ggplot2
ggplot(mpg, aes(x=cty)) +
geom_bar() +
labs(x = "City mileage")
# Data Viz with ggplot2
ggplot(mpg, aes(x=cty)) +
geom_smooth() +
labs(x = "City mileage")
# Data Viz with ggplot2
ggplot(mpg, aes(x=cty)) +
geom_boxplot() +
labs(x = "City mileage")
# Data Viz with ggplot2
ggplot(mpg, aes(x=cty)) +
geom_freqpoly() +
labs(x = "City mileage")
ggplot(mpg, aes(x=cty)) +
geom_freqpoly() +
geom_histogram() +
labs(x = "City mileage")
ggplot(mpg, aes(x = cty,
y = hwy)) +
geom_point() +
geom_smooth(method = "lm")
ggplot(mpg, aes(x = cty,
y = hwy)) +
geom_point()
ggplot(mpg, aes(x = cty,
y = hwy)) +
geom_point() +
geom_smooth(method = "lm")
ggplot(mpg, aes(x = cty,
y = hwy,
color = class)) +
geom_point()
ggplot(mpg, aes(x = cty,
y = hwy,
color = class)) +
geom_point() +
scale_color_brewer(palette = "Dark2")
mpg %>%
group_by(class) %>%
summarise(mean(cty),
median(cty))
ggplot(mpg, aes(x = cty,
y = hwy)) +
geom_point() +
geom_smooth(method = "lm")
ggplot(mpg, aes(x = cty,
y = hwy,
color = class)) +
geom_point() +
geom_smooth(method = "lm")
ggplot(mpg, aes(x = cty,
y = hwy,
color = class)) +
geom_point() +
geom_smooth(method = "lm") +
scale_color_brewer(palette = "Dark2")
mpg %>%
group_by(class) %>%
summarise(mean(cty),
median(cty))
mpg %>%
group_by(class) %>%
summarise(meanCty <- mean(cty),
medCTy <- mean(hwy))
mpg %>%
group_by(class) %>%
mutate(meanCty <- mean(cty),
medCty <- mean(hwy))
summarise(meanCty,medCty)
mpg %>%
group_by(class) %>%
mutate(meanCty <- mean(cty),
medCty <- mean(hwy)) %>%
summarise(meanCty,medCty)
mpg %>%
group_by(class) %>%
mutate(meanCty = mean(cty),
medCty = mean(hwy)) %>%
summarise(meanCty, medCty)
#clear the environment
rm(list = ls())
#ANN
# Install and load required packages if not already installed
install.packages(c('neuralnet','keras','tensorflow'),dependencies = T)
install.packages("tidyverse")
library(neuralnet)
# Load the required library
library(tidyverse)
library(neuralnet)
#preprocess iris dataset
str(iris)
#preprocess iris dataset
glipsme(iris)
#preprocess iris dataset
glimpse(iris)
iris <- iris %>% mutate_if(is.character, as.factor)
#The `summary` function is used for statistical analysis and data distribution.
summary(iris)
#preprocess iris dataset
glimpse(iris)
#clear the environment
rm(list = ls())
#preprocess iris dataset
glimpse(iris)
iris <- iris %>% mutate_if(is.character, as.factor)
#preprocess iris dataset
glimpse(iris)
view(iris)
#The `summary` function is used for statistical analysis and data distribution.
summary(iris)
# Create an index for splitting the data (80% training, 20% testing)
data_rows <- floor(0.80 * nrow(iris))
train_indices <- sample(c(1:nrow(iris)), data_rows)
# Create training and testing datasets
train_data <- iris[train_indices,]
test_data <- iris[-train_indices,]
model = neuralnet(
Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=train_data,
hidden=c(4,2),
linear.output = FALSE
)
# Plot the ANN architecture
plot(model,rep = "best")
model = neuralnet(
Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=train_data,
hidden=c(4,2),
linear.output = FALSE
)
# Plot the ANN architecture
plot(model,rep = "best")
pred <- predict(model, test_data)
labels <- c("setosa", "versicolor", "virginca")
prediction_label <- data.frame(max.col(pred)) %>%
mutate(pred=labels[max.col.pred.]) %>%
select(2) %>%
unlist()
# Create a confusion matrix
conf_matrix <- table(test_data$Species, prediction_label)
# Print the confusion matrix
print(conf_matrix)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
recall <- diag(conf_matrix) / colSums(conf_matrix)
f_score <- 2 * (precision * recall) / (precision + recall)
cat("Accuracy:", accuracy, "\n")
cat("Precision (per class):", paste(precision, collapse = ", "), "\n")
cat("Recall (per class):", paste(recall, collapse = ", "), "\n")
cat("F-score (per class):", paste(f_score, collapse = ", "), "\n")
model = neuralnet(
Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=train_data,
hidden=c(4,2),
linear.output = FALSE
)
# Plot the ANN architecture
plot(model,rep = "best")
pred <- predict(model, test_data)
labels <- c("setosa", "versicolor", "virginca")
prediction_label <- data.frame(max.col(pred)) %>%
mutate(pred=labels[max.col.pred.]) %>%
select(2) %>%
unlist()
# Create a confusion matrix
conf_matrix <- table(test_data$Species, prediction_label)
# Print the confusion matrix
print(conf_matrix)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
recall <- diag(conf_matrix) / colSums(conf_matrix)
f_score <- 2 * (precision * recall) / (precision + recall)
# Print evaluation metrics
cat("Accuracy:", accuracy, "\n")
cat("Precision (per class):", paste(precision, collapse = ", "), "\n")
cat("Recall (per class):", paste(recall, collapse = ", "), "\n")
cat("F-score (per class):", paste(f_score, collapse = ", "), "\n")
model = neuralnet(
Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=train_data,
hidden=c(4,2),
linear.output = FALSE
)
# Plot the ANN architecture
plot(model,rep = "best")
model = neuralnet(
Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=train_data,
hidden=c(4,2),
linear.output = FALSE
)
# Plot the ANN architecture
plot(model,rep = "best")
# Plot the ANN architecture
plot(model,rep = "best")
pred <- predict(model, test_data)
labels <- c("setosa", "versicolor", "virginca")
prediction_label <- data.frame(max.col(pred)) %>%
mutate(pred=labels[max.col.pred.]) %>%
select(2) %>%
unlist()
# Create a confusion matrix
conf_matrix <- table(test_data$Species, prediction_label)
# Print the confus
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
recall <- diag(conf_matrix) / colSums(conf_matrix)
f_score <- 2 * (precision * recall) / (precision + recall)
# Print evaluation metrics
cat("Accuracy:", accuracy, "\n")
cat("Precision (per class):", paste(precision, collapse = ", "), "\n")
cat("Recall (per class):", paste(recall, collapse = ", "), "\n")
cat("F-score (per class):", paste(f_score, collapse = ", "), "\n")
model = neuralnet(
Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=train_data,
hidden=c(4,2),
linear.output = FALSE
)
# Plot the ANN architecture
plot(model,rep = "best")
pred <- predict(model, test_data)
labels <- c("setosa", "versicolor", "virginca")
prediction_label <- data.frame(max.col(pred)) %>%
mutate(pred=labels[max.col.pred.]) %>%
select(2) %>%
unlist()
# Create a confusion matrix
conf_matrix <- table(test_data$Species, prediction_label)
# Print the confusion matrix
print(conf_matrix)
# Calculate evaluation metrics
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
recall <- diag(conf_matrix) / colSums(conf_matrix)
f_score <- 2 * (precision * recall) / (precision + recall)
# Print evaluation metrics
cat("Accuracy:", accuracy, "\n")
cat("Precision (per class):", paste(precision, collapse = ", "), "\n")
cat("Recall (per class):", paste(recall, collapse = ", "), "\n")
cat("F-score (per class):", paste(f_score, collapse = ", "), "\n")
#clear the environment
rm(list = ls())
#ANN
# Install and load required packages if not already installed
install.packages(c('neuralnet','keras','tensorflow'),dependencies = T)
install.packages("tidyverse")
install.packages(c("neuralnet", "keras", "tensorflow"), dependencies = T)
# Install and load required packages if not already installed
install.packages(c('neuralnet','keras','tensorflow'),dependencies = T)
install.packages("tidyverse")
# Load the required library
library(tidyverse)
library(neuralnet)
#preprocess iris dataset
glimpse(iris)
view(iris)
iris <- iris %>% mutate_if(is.character, as.factor)
#The `summary` function is used for statistical analysis and data distribution.
summary(iris)
# Set a seed for reproducibility
set.seed(245)
# Create an index for splitting the data (80% training, 20% testing)
data_rows <- floor(0.80 * nrow(iris))
train_indices <- sample(c(1:nrow(iris)), data_rows)
# Create training and testing datasets
train_data <- iris[train_indices,]
test_data <- iris[-train_indices,]
# Define the formula for the neural network model
# Create an artificial neural network model
model = neuralnet(
Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=train_data,
hidden=c(4,2),
linear.output = FALSE
)
# Plot the ANN architecture
plot(model,rep = "best")
# Evaluation of the model
pred <- predict(model, test_data)
labels <- c("setosa", "versicolor", "virginca")
prediction_label <- data.frame(max.col(pred)) %>%
mutate(pred=labels[max.col.pred.]) %>%
select(2) %>%
unlist()
# Create a confusion matrix
conf_matrix <- table(test_data$Species, prediction_label)
# Print the confusion matrix
print(conf_matrix)
# Calculate evaluation metrics
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
recall <- diag(conf_matrix) / colSums(conf_matrix)
f_score <- 2 * (precision * recall) / (precision + recall)
# Print evaluation metrics
cat("Accuracy:", accuracy, "\n")
cat("Precision (per class):", paste(precision, collapse = ", "), "\n")
cat("Recall (per class):", paste(recall, collapse = ", "), "\n")
cat("F-score (per class):", paste(f_score, collapse = ", "), "\n")
model = neuralnet(
Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=train_data,
hidden=c(4,2),
linear.output = FALSE
)
library(neuralnet)
# Load the required library
library(tidyverse)
#preprocess iris dataset
glimpse(iris)
view(iris)
iris <- iris %>% mutate_if(is.character, as.factor)
#The `summary` function is used for statistical analysis and data distribution.
summary(iris)
# Set a seed for reproducibility
set.seed(245)
# Create an index for splitting the data (80% training, 20% testing)
data_rows <- floor(0.80 * nrow(iris))
train_indices <- sample(c(1:nrow(iris)), data_rows)
# Create training and testing datasets
train_data <- iris[train_indices,]
test_data <- iris[-train_indices,]
# Define the formula for the neural network model
# Create an artificial neural network model
model = neuralnet(
Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=train_data,
hidden=c(4,2),
linear.output = FALSE
)
# Plot the ANN architecture
plot(model,rep = "best")
# Evaluation of the model
pred <- predict(model, test_data)
labels <- c("setosa", "versicolor", "virginca")
prediction_label <- data.frame(max.col(pred)) %>%
mutate(pred=labels[max.col.pred.]) %>%
select(2) %>%
unlist()
# Create a confusion matrix
conf_matrix <- table(test_data$Species, prediction_label)
# Print the confusion matrix
print(conf_matrix)
# Calculate evaluation metrics
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
recall <- diag(conf_matrix) / colSums(conf_matrix)
f_score <- 2 * (precision * recall) / (precision + recall)
# Print evaluation metrics
cat("Accuracy:", accuracy, "\n")
cat("Precision (per class):", paste(precision, collapse = ", "), "\n")
cat("Recall (per class):", paste(recall, collapse = ", "), "\n")
cat("F-score (per class):", paste(f_score, collapse = ", "), "\n")
model = neuralnet(
Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=train_data,
hidden=c(4,5),
linear.output = FALSE
)
plot(model,rep = "best")
model = neuralnet(
Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=train_data,
hidden=c(7,5),
linear.output = FALSE
)
plot(model,rep = "best")
model = neuralnet(
Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=train_data,
hidden=c(7,5,3),
linear.output = FALSE
)
# Plot the ANN architecture
plot(model,rep = "best")
# Evaluation of the model
pred <- predict(model, test_data)
labels <- c("setosa", "versicolor", "virginca")
prediction_label <- data.frame(max.col(pred)) %>%
mutate(pred=labels[max.col.pred.]) %>%
select(2) %>%
unlist()
# Create a confusion matrix
conf_matrix <- table(test_data$Species, prediction_label)
# Print the confusion matrix
print(conf_matrix)
# Calculate evaluation metrics
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
recall <- diag(conf_matrix) / colSums(conf_matrix)
f_score <- 2 * (precision * recall) / (precision + recall)
# Print evaluation metrics
cat("Accuracy:", accuracy, "\n")
cat("Precision (per class):", paste(precision, collapse = ", "), "\n")
cat("Recall (per class):", paste(recall, collapse = ", "), "\n")
cat("F-score (per class):", paste(f_score, collapse = ", "), "\n")
model = neuralnet(
Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=train_data,
hidden=c(7,5,3,9),
linear.output = FALSE
)
# Plot the ANN architecture
plot(model,rep = "best")
# Clear the environment
rm(list = ls())
# Load necessary libraries
library(keras)
library(tensorflow)
library(Metrics)
library(pROC)
setwd('C:/Users/syahi/Documents/Deep-Chest-Diagnostics/Datasets')
getwd()
getwd()
path_to_data <- 'C:/Users/syahi/Documents/Deep-Chest-Diagnostics/Datasets/chest_xray'
# Preprocess and load the dataset
train_data_generator <- image_data_generator(rescale = 1/255)
install_tensorflow()
install_keras()
